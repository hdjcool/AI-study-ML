{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3dJA1bnlxaC"
   },
   "source": [
    "---   \n",
    "\n",
    "# IEEE-CIS Fraud Detection의 불균형 데이터\n",
    "    - STEP 1 : IEEE-CIS Fraud Detection 데이터 불러오기 및 전처리\n",
    "    - STEP 2 : Light GBM 기본 모델 테스트\n",
    "    - STEP 3-4 : Oversampling 수행\n",
    "\n",
    "- 작성자: 김태영 감수자\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkoX82EulxaS"
   },
   "source": [
    "---\n",
    "\n",
    "## STEP 1~4. IEEE-CIS Fraud Detection의 불균형 데이터 문제\n",
    "\n",
    "### 배경\n",
    "실제 캐글에서 개최된 부정거래 예측 대회인 IEEE-CIS Fraud Detection에서 사용된 데이터를 가지고 불균형 데이터 분석을 수행해보고, 간단한 예측 모델을 만들어보겠습니다. 예측 모델의 정확도를 높이기 위해서 본 파트에서 배운 여러가지 불균형 데이터 처리 기법을 적용해보고 그 결과를 살펴보겠습니다.\n",
    "\n",
    "### 목표\n",
    "- IEEE-CIS Fraud Detection 데이터 불러오기 및 전처리\n",
    "- Light GBM 기본 모델 테스트\n",
    "- SMOTE을 이용한 Oversampling 수행\n",
    "- BLSM을 이용한 Oversampling 수행\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp1AQUStlxaT"
   },
   "source": [
    "### STEP 1. IEEE-CIS Fraud Detection 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7pbOET88kH-"
   },
   "source": [
    " IEEE-CIS Fraud Detection 데이터를 불러와서 전처리를 수행합니다. \n",
    "\n",
    "* https://www.kaggle.com/c/ieee-fraud-detection의 data 탭에서 train_transaction.csv와 test_transaction.csv를 다운로드 함\n",
    "* 카테고리형 및 결측치 처리 \n",
    "* 본 파트에서 데이터 전처리 과정은 평가에 포함되지 않으므로 소스코드 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-_J43HCBlxaT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03499000914417313"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train_transaction.csv\")\n",
    "test = pd.read_csv(\"test_transaction.csv\")\n",
    "\n",
    "train[\"isFraud\"].mean() #  0.03499000914417313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DGZNUhoE-j6W"
   },
   "outputs": [],
   "source": [
    "# generate time of day\n",
    "train[\"Time of Day\"] = np.floor(train[\"TransactionDT\"]/3600/183)\n",
    "test[\"Time of Day\"] = np.floor(test[\"TransactionDT\"]/3600/183)\n",
    "\n",
    "# drop columns\n",
    "train.drop(\"TransactionDT\",axis=1,inplace=True)\n",
    "test.drop(\"TransactionDT\",axis=1,inplace=True)\n",
    "\n",
    "# define continuous and categorical variables\n",
    "cont_vars = [\"TransactionAmt\"]\n",
    "cat_vars = [\"ProductCD\",\"addr1\",\"addr2\",\"P_emaildomain\",\"R_emaildomain\",\"Time of Day\"] + [col for col in train.columns if \"card\" in col]\n",
    "\n",
    "# set training and testing set\n",
    "x_train = train[cont_vars + cat_vars].copy()\n",
    "y_train = train[\"isFraud\"].copy()\n",
    "x_test = train[cont_vars + cat_vars].copy()\n",
    "y_test = train[\"isFraud\"].copy()\n",
    "\n",
    "# process cont_vars\n",
    "# scale values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train[\"TransactionAmt\"] = scaler.fit_transform(x_train[\"TransactionAmt\"].values.reshape(-1,1))\n",
    "x_test[\"TransactionAmt\"] = scaler.transform(x_test[\"TransactionAmt\"].values.reshape(-1,1))\n",
    "\n",
    "# reduce cardinality of categorical variables\n",
    "idx_list = x_train[\"card1\"].value_counts()[x_train[\"card1\"].value_counts()<=100].index.tolist()\n",
    "x_train.loc[x_train[\"card1\"].isin(idx_list),\"card1\"] = \"Others\"\n",
    "x_test.loc[x_test[\"card1\"].isin(idx_list),\"card1\"] = \"Others\"\n",
    "\n",
    "# convert to numerical value for modelling\n",
    "def categorify(df, cat_vars):\n",
    "    categories = {}\n",
    "    for cat in cat_vars:\n",
    "        df[cat] = df[cat].astype(\"category\").cat.as_ordered()\n",
    "        categories[cat] = df[cat].cat.categories\n",
    "    return categories\n",
    "\n",
    "def apply_test(test,categories):\n",
    "    for cat, index in categories.items():\n",
    "        test[cat] = pd.Categorical(test[cat],categories=categories[cat],ordered=True)\n",
    "\n",
    "# convert to integers\n",
    "categories = categorify(x_train,cat_vars)\n",
    "apply_test(x_test,categories)\n",
    "\n",
    "for cat in cat_vars:\n",
    "    x_train[cat] = x_train[cat].cat.codes+1\n",
    "    x_test[cat] = x_test[cat].cat.codes+1\n",
    "\n",
    "\n",
    "\n",
    "# fill missing\n",
    "x_train[cat_vars] = x_train[cat_vars].fillna(\"Missing\")\n",
    "x_test[cat_vars] = x_test[cat_vars].fillna(\"Missing\")\n",
    "for cat, index in categories.items():\n",
    "    test[cat] = pd.Categorical(test[cat],categories=categories[cat],ordered=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dgkizs0mDhhF"
   },
   "source": [
    "평가 코드는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o6zdsCjC-MFQ"
   },
   "outputs": [],
   "source": [
    "def model_evaluation(label, predict):\n",
    "    cf_matrix = confusion_matrix(label, predict)\n",
    "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
    "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
    "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
    "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    print(\"Model_Evaluation with Label:1\")\n",
    "    print(\"Accuracy: \", Accuracy)\n",
    "    print(\"Precision: \", Precision)\n",
    "    print(\"Recall: \", Recall)\n",
    "    print(\"F1-Score: \", F1_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P78HuQQQlxaW"
   },
   "source": [
    "### STEP 2. Light GBM 기본 모델 테스트\n",
    "\n",
    "Light GBM 기본 모델로 불균형 데이터 처리를 수행합니다.\n",
    "\n",
    "* 학습 데이터를 LightGBM 모델에 맞게 변환함\n",
    "* LightGBM 모델 학습함\n",
    "* LightGBM 모델 평가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "X5PfKrevlxaX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Evaluation with Label:1\n",
      "Accuracy:  0.9650099908558268\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "F1-Score:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 수행\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import lightgbm as lgb\n",
    "lgb_dtrain = lgb.Dataset(data = pd.DataFrame(x_train), label = pd.DataFrame(y_train)) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 50, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'multiclass', # 목적 함수\n",
    "            'num_class': len(set(pd.DataFrame(y_train))) + 1} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행\n",
    "lgb_model_predict = np.argmax(lgb_model.predict(x_test), axis = 1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측\n",
    "model_evaluation(y_test, lgb_model_predict) # 모델 분류 결과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnUfQKcrlxab"
   },
   "source": [
    "### STEP 3. SMOTE을 이용한 Oversampling 수행\n",
    "\n",
    "SMOTE를 이용하여 Oversampling를 수행한 후 Light GBM 기본 모델로 평가해봅니다.\n",
    "\n",
    "* SMOTE을 이용하여 Oversampling 수행\n",
    "* 학습 데이터를 LightGBM 모델에 맞게 변환함\n",
    "* LightGBM 모델 학습함\n",
    "* LightGBM 모델 평가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3NjfsrdOlxab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (590540, 13)\n",
      "y_train:  (590540,)\n",
      "x_test:  (590540, 13)\n",
      "y_test:  (590540,)\n"
     ]
    }
   ],
   "source": [
    "# 기존의 X_train, y_train, X_test, y_test의 형태 확인\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_test: \", x_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5ZIPxIsZD2Fy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 20663\n",
      "Before OverSampling, counts of label '0': 569877 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '1': 170963\n",
      "After OverSampling, counts of label '0': 569877\n"
     ]
    }
   ],
   "source": [
    "# SMOTE 수행\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) # y_train 중 레이블 값이 1인 데이터의 개수\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) # y_train 중 레이블 값이 0 인 데이터의 개수\n",
    "\n",
    "sm = SMOTE(random_state = 42, ratio = 0.3) # SMOTE 알고리즘, 비율 증가\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train.ravel()) # Over Sampling 진행\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zaMdon4ND4S6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, the shape of X_train: (590540, 13)\n",
      "Before OverSampling, the shape of y_train: (590540,)\n",
      "After OverSampling, the shape of X_train: (740840, 13)\n",
      "After OverSampling, the shape of y_train: (740840,)\n"
     ]
    }
   ],
   "source": [
    "# SMOTE 전후 데이터 형태 확인\n",
    "print(\"Before OverSampling, the shape of X_train: {}\".format(x_train.shape)) # SMOTE 적용 이전 데이터 형태\n",
    "print(\"Before OverSampling, the shape of y_train: {}\".format(y_train.shape)) # SMOTE 적용 이전 데이터 형태\n",
    "print('After OverSampling, the shape of X_train: {}'.format(x_train_res.shape)) # SMOTE 적용 결과 확인\n",
    "print('After OverSampling, the shape of y_train: {}'.format(y_train_res.shape)) # # SMOTE 적용 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CSdZeyrJD6EW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Evaluation with Label:1\n",
      "Accuracy:  0.9650099908558268\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "F1-Score:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 수행\n",
    "lgb_dtrain2 = lgb.Dataset(data = pd.DataFrame(x_train_res), label = pd.DataFrame(y_train_res)) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param2 = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 50, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'multiclass', # 목적 함수\n",
    "            'num_class': len(set(pd.DataFrame(y_train_res))) + 1} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model2 = lgb.train(params = lgb_param2, train_set = lgb_dtrain2) # 학습 진행\n",
    "lgb_model2_predict = np.argmax(lgb_model2.predict(x_test), axis = 1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측\n",
    "model_evaluation(y_test, lgb_model2_predict) # 모델 분류 평가 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTf7FnOClxaf"
   },
   "source": [
    "### STEP 4. BLSM을 이용한 Oversampling 수행\n",
    "\n",
    "BLSM을 이용하여 Oversampling를 수행한 후 Light GBM 기본 모델로 평가해봅니다.\n",
    "\n",
    "* BLSM을 이용하여 Oversampling 수행\n",
    "* 학습 데이터를 LightGBM 모델에 맞게 변환함\n",
    "* LightGBM 모델 학습함\n",
    "* LightGBM 모델 평가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AV0Vrd2Elxaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# BLSM 수행\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "sm4 = BorderlineSMOTE(random_state = 42, sampling_strategy = 0.6) # BLSM 알고리즘 적용\n",
    "x_train_res4, y_train_res4 = sm4.fit_sample(x_train, y_train.ravel()) # Over Sampling 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L5bCvvGiD_0y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drogpard\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Evaluation with Label:1\n",
      "Accuracy:  0.9261201612083856\n",
      "Precision:  0.19434092844974446\n",
      "Recall:  0.35333688235009436\n",
      "F1-Score:  0.25075990451821195\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 수행\n",
    "lgb_dtrain5 = lgb.Dataset(data = pd.DataFrame(x_train_res4), label = pd.DataFrame(y_train_res4)) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param5 = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 50, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'multiclass', # 목적 함수\n",
    "            'num_class': len(set(pd.DataFrame(y_train_res4))) + 1} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model5 = lgb.train(params = lgb_param5, train_set = lgb_dtrain5) # 학습 진행\n",
    "lgb_model5_predict = np.argmax(lgb_model5.predict(x_test), axis = 1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측\n",
    "model_evaluation(y_test, lgb_model5_predict) # 모델 분류 평가 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part5_미니프로젝트6(문제).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
